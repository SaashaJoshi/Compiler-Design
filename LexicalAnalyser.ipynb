{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/saasha/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = { '=': 'Assignment Operator', '+': 'Additon Operator', '-' : 'Substraction Operator', '/' : 'Division Operator', '*': 'Multiplication Operator', '++' : 'increment Operator', '--' : 'Decrement Operator'}\n",
    "\n",
    "compound_assignment = {'+=': 'Addition Assignment', '-=': 'Subtraction Assignment', '*=': 'Multiplication Assignment', '/=': 'Division Assignment'}\n",
    "\n",
    "comments = {r'//': 'Single Line Comment', r'/*': 'Multiline Comment Start', r'*/': 'Multiline Comment End', '/**/': 'Empty Multiline comment'}\n",
    "\n",
    "ppdirective = {'#include': 'Pre-processor Directive', '#define': 'Macro Directive', '#undef': 'Undefine Macro Directive'}\n",
    "\n",
    "macros = {r'#\\w+' : 'Macro / Preprocessor Directive'}\n",
    "\n",
    "header = {'.h': 'Header File'}\n",
    "\n",
    "sp_header_files = {'<iostream>': 'Input Output Stream', '<iomanip.h>': 'Input Output Manipulation', '<stdio.h>':'Standard Input Output Header', '<stdlib.h>': 'Standard Library Header', '<string.h>':'String Manipulation Library', '<fstream.h>': 'File stream', '<conio.h>': 'Console Input Output Header', '<math.h>': 'Math Header'}\n",
    "\n",
    "datatype = {'int': 'Integer','float' : 'Floating Point', 'char': 'Character', 'long': 'Long Integer'}\n",
    "\n",
    "keyword = {'return' : 'Return Keyword', 'main': 'Main Function'}\n",
    "\n",
    "delimiter = {';':'Line Terminator Symbol (Semi-colon)'}\n",
    "\n",
    "blocks = {'{' : 'Blocked Statement Body Open', '}': 'Blocked Statement Body Closed'}\n",
    "\n",
    "builtin_functions = {'printf': 'Print / Output Statement', 'scanf': 'Input Statement', 'cin': 'Input Statement', 'cout': 'Output Statement'}\n",
    "\n",
    "loop_statements = {'if': 'If Statement', 'else': 'Else Statement', 'for': 'For Loop Statement', 'while': 'While Loop Statement', 'switch': 'Switch Case Statements', 'case': 'Switch Case Statements'}\n",
    "\n",
    "non_identifiers = list('_-+/*`~!@#$%^&*()=|\":;{}[]<>?/')\n",
    "\n",
    "numerals = ['0','1','2','3','4','5','6','7','8','9','10']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Line 1 :  #include <stdio.h>\n",
      "Tokens:  ['#', 'include', '<', 'stdio.h', '>']\n",
      "Token Properties: \n",
      "#\\w+\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'#\\\\w+'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-834a72739949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'#\\w+'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppdirective\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'('\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '#\\\\w+'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "\n",
    "f = open(\"c_code.c\", \"r\")\n",
    "\n",
    "i = f.read()\n",
    "\n",
    "dataFlag = False\n",
    "line_count = 0\n",
    "special_line_count = []\n",
    "\n",
    "program = i.split('\\n')    # Split program into lines\n",
    "#print(program)\n",
    "\n",
    "# Remove Whitespaces\n",
    "for line in program:\n",
    "    line = line.strip()\n",
    "    line_count = line_count + 1\n",
    "    print()\n",
    "    print('Line', line_count, ': ', line)\n",
    "    \n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    tokens = list(OrderedDict.fromkeys(tokens))\n",
    "    print('Tokens: ', tokens)\n",
    "    \n",
    "#     for keys in builtin_keys:\n",
    "#         if keys in line:\n",
    "#             #print(keys)\n",
    "#             special_line_count.append(line_count)\n",
    "            \n",
    "#     for keys in loop_keys:\n",
    "#         if keys in line:\n",
    "#             #print(keys)\n",
    "#             special_line_count.append(line_count)\n",
    "            \n",
    "#     #print(special_line_count)\n",
    "            \n",
    "#     if line_count in special_line_count:\n",
    "#         tokens = []\n",
    "#         for word in re.split(r'(\\d+|\\W+)', line):\n",
    "#             tokens.append(word)\n",
    "#         tokens = [line]\n",
    "#         tokens = nltk.word_tokenize(line)\n",
    "#         print('Tokens: ', tokens)    \n",
    "#         print()\n",
    "#         #break\n",
    "#     else:\n",
    "#         tokens = line.split()\n",
    "#         print('Tokens: ', tokens)\n",
    "#         print()\n",
    "#         #break\n",
    "\n",
    "\n",
    "# Token Properties\n",
    "    print('Token Properties: ')\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in operators:\n",
    "            print(operators[token], '(', token, ')')\n",
    "        if token in compound_assignment:\n",
    "            print(compound_assignment[token], '(', token, ')')\n",
    "        if token in comments:\n",
    "            print(comments[token], '(', token, ')')\n",
    "        if token in datatype:\n",
    "            print(datatype[token], '(', token, ')')\n",
    "        if token in keyword:\n",
    "            print(keyword[token], '(', token, ')')\n",
    "        if token in delimiter:\n",
    "            print(delimiter[token], '(', token, ')')\n",
    "        if token in blocks:\n",
    "            print(blocks[token], '(', token, ')')\n",
    "        if token in builtin_functions:\n",
    "            print(builtin_functions[token], '(', token, ')')\n",
    "        if token in loop_statements:\n",
    "            print(loop_statements[token], '(', token, ')')\n",
    "#         if token in macros:\n",
    "#             print(macros[token], '(', token, ')')\n",
    "        if token == '#':\n",
    "            word = r'#\\w+'\n",
    "            print(word)\n",
    "            print(ppdirective[word], '(', word, ')')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
